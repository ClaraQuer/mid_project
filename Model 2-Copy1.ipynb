{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "66bd1bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import country_converter as coco\n",
    "import re\n",
    "import pandas_profiling as pp\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "import getpass\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5653192a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 2000)\n",
    "pd.set_option('display.max_columns', 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0f8337",
   "metadata": {},
   "source": [
    "### Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "66b1adc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cd58c896",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data[~data['polity'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e3c50eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>continent</th>\n",
       "      <th>region</th>\n",
       "      <th>iso3</th>\n",
       "      <th>country_name</th>\n",
       "      <th>indicator_id</th>\n",
       "      <th>value</th>\n",
       "      <th>democ</th>\n",
       "      <th>autoc</th>\n",
       "      <th>polity</th>\n",
       "      <th>indicator_name</th>\n",
       "      <th>dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Asia</td>\n",
       "      <td>Southern Asia</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>European Union Membership (True/False)</td>\n",
       "      <td>International Organisations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Asia</td>\n",
       "      <td>Southern Asia</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>United Nations Membership (True/False)</td>\n",
       "      <td>International Organisations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Asia</td>\n",
       "      <td>Southern Asia</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>OECD Membership (True/False)</td>\n",
       "      <td>International Organisations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Asia</td>\n",
       "      <td>Southern Asia</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>21806</td>\n",
       "      <td>2621.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Refugees by country of origin (thousands)</td>\n",
       "      <td>Human Security</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Asia</td>\n",
       "      <td>Southern Asia</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>23806</td>\n",
       "      <td>25.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Population with at least some secondary educat...</td>\n",
       "      <td>Education</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  continent         region iso3 country_name  indicator_id   value  democ  \\\n",
       "0      Asia  Southern Asia  AFG  Afghanistan             1     0.0    1.0   \n",
       "1      Asia  Southern Asia  AFG  Afghanistan             2     1.0    1.0   \n",
       "2      Asia  Southern Asia  AFG  Afghanistan             3     0.0    1.0   \n",
       "3      Asia  Southern Asia  AFG  Afghanistan         21806  2621.1    1.0   \n",
       "4      Asia  Southern Asia  AFG  Afghanistan         23806    25.1    1.0   \n",
       "\n",
       "   autoc  polity                                     indicator_name  \\\n",
       "0    2.0    -1.0             European Union Membership (True/False)   \n",
       "1    2.0    -1.0             United Nations Membership (True/False)   \n",
       "2    2.0    -1.0                       OECD Membership (True/False)   \n",
       "3    2.0    -1.0          Refugees by country of origin (thousands)   \n",
       "4    2.0    -1.0  Population with at least some secondary educat...   \n",
       "\n",
       "                     dimension  \n",
       "0  International Organisations  \n",
       "1  International Organisations  \n",
       "2  International Organisations  \n",
       "3               Human Security  \n",
       "4                    Education  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe12bea",
   "metadata": {},
   "source": [
    "### Filtering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "db1f9838",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r clean_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8379fc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = data2[data2['indicator_id'].isin(clean_id)].copy()\n",
    "clean_data['indicator_id'] = clean_data['indicator_id'].astype('str')\n",
    "clean_df = clean_data.pivot(index = ['country_name', 'continent', 'region', 'polity'], \n",
    "                                    columns= ['indicator_id'], values = 'value').reset_index().copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109bcf13",
   "metadata": {},
   "source": [
    "I only want the indicator_ids that do not have high collinearity with eachother, so I filter them based on the list I created in the previous notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "89ec353d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "indicator_id\n",
       "country_name     0\n",
       "continent        0\n",
       "region           0\n",
       "polity           0\n",
       "1                0\n",
       "100806           0\n",
       "101406          40\n",
       "101706          21\n",
       "102006          67\n",
       "110806           0\n",
       "110906           0\n",
       "111106           9\n",
       "111306          15\n",
       "117806          67\n",
       "117906          67\n",
       "118006          67\n",
       "121106           0\n",
       "121206           0\n",
       "122006           0\n",
       "123406           7\n",
       "123506           2\n",
       "123806          13\n",
       "127606          13\n",
       "128106           8\n",
       "128306           4\n",
       "132706           0\n",
       "133006          24\n",
       "133206           4\n",
       "135106          22\n",
       "137906          12\n",
       "138806          22\n",
       "140606           0\n",
       "142506          67\n",
       "143306           6\n",
       "146206           2\n",
       "147206          38\n",
       "147906          57\n",
       "148206           0\n",
       "149406           1\n",
       "150706           0\n",
       "164406          19\n",
       "167106          80\n",
       "169706           0\n",
       "169806           0\n",
       "170106          45\n",
       "174406           4\n",
       "175106           0\n",
       "175206          42\n",
       "175506          27\n",
       "175706          13\n",
       "177106           1\n",
       "177206           0\n",
       "178306           4\n",
       "181106          14\n",
       "181206          21\n",
       "181606           0\n",
       "181706           1\n",
       "182206           0\n",
       "183206          34\n",
       "183406          67\n",
       "2                0\n",
       "21806            0\n",
       "24106            8\n",
       "27706            0\n",
       "3                0\n",
       "31706            0\n",
       "38506           67\n",
       "39006           73\n",
       "43006            0\n",
       "45106            0\n",
       "46006            0\n",
       "46106           22\n",
       "46206           23\n",
       "48706            0\n",
       "48806            0\n",
       "49006            0\n",
       "52606           12\n",
       "53506            3\n",
       "61006            9\n",
       "63206           12\n",
       "63406           27\n",
       "64306            0\n",
       "64406            0\n",
       "65606            8\n",
       "69206            0\n",
       "71606           21\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eae3f96",
   "metadata": {},
   "source": [
    "## Predicting function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aadb30e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df):\n",
    "    \n",
    "    # First, I get the names of all the columns that contain NaN values into a list. \n",
    "    # I start by looking for the number of NaN values per indicator and I sort them in ascending order,\n",
    "    # so I will start predicting with the ones that have fewer NaNs.\n",
    "    \n",
    "    nan = df.isna().sum().sort_values()\n",
    "    nan = pd.DataFrame(nan).reset_index()\n",
    "    nan.columns = ['indicator_id', 'nans']\n",
    "    nans = []\n",
    "    \n",
    "    # I define the length of the column in a list so I can iterate on its range\n",
    "    \n",
    "    lst = nan['indicator_id'].to_list()\n",
    "    \n",
    "    # With a for loop, I append all the column names with NaN values greater than 0 into a list, in the desired order. \n",
    "\n",
    "    for i in range(len(lst)):\n",
    "        if nan['nans'][i] > 0:\n",
    "            nans.append(nan['indicator_id'][i])\n",
    "    \n",
    "    # I iterate on the nans list, creating a dataframe with only the numerical data and dropping the NaNs. \n",
    "    # After that, I re-append the one where I will be predicting (it was dropped because it has NaNs).\n",
    "    \n",
    "    for i in nans:\n",
    "        \n",
    "        num = df.select_dtypes(np.number).dropna(axis = 1)\n",
    "        num[i] = df[i]\n",
    "        \n",
    "        # I create my training sample with the values for which my column is not NaN, I do an X/y split and I encode the X.\n",
    "        \n",
    "        id_with_num = num[num[i].notna()]\n",
    "        X_id = id_with_num.drop([i],axis=1)\n",
    "        y_id = id_with_num[i]\n",
    "        X_normalized_id = pd.DataFrame(MinMaxScaler().fit_transform(X_id), columns=X_id.columns)\n",
    "        \n",
    "        # I fit my model into the train sample.\n",
    "        \n",
    "        LR = LinearRegression()\n",
    "        LR.fit(X_normalized_id, y_id)\n",
    "        \n",
    "        # I create a second dataframe with all the values (including NaNs), this will be my test sample. \n",
    "        # I X/y split, scale and use the model to predict the y. \n",
    "        \n",
    "        X_all = num.drop([i],axis=1)\n",
    "        X_normalized_all = pd.DataFrame(MinMaxScaler().fit_transform(X_all), columns=X_all.columns)\n",
    "        y_all = num[i]\n",
    "        \n",
    "        # I create a new column with the predictions.\n",
    "        \n",
    "        i_pred = pd.Series(LR.predict(X_normalized_all), name='predicted_' + i)\n",
    "        df = pd.concat([df, i_pred], axis=1)\n",
    "        \n",
    "        # In the last column, I get the data frrom the original column and fill the NaNs with the prediction column. \n",
    "        # Then I drop the other 2, and now I have no NaN values in the dataframe and I haven't lost any data. \n",
    "        \n",
    "        df['final_' + i] =  np.where(df[i].isna(), df['predicted_' + i], df[i])\n",
    "        df.drop([i, 'predicted_' + i], axis = 1, inplace = True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c75f4f34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country_name    0\n",
       "continent       0\n",
       "region          0\n",
       "polity          0\n",
       "1               0\n",
       "100806          0\n",
       "110806          0\n",
       "110906          0\n",
       "121106          0\n",
       "121206          0\n",
       "122006          0\n",
       "132706          0\n",
       "140606          0\n",
       "148206          0\n",
       "150706          0\n",
       "169706          0\n",
       "169806          0\n",
       "175106          0\n",
       "177206          0\n",
       "181606          0\n",
       "182206          0\n",
       "2               0\n",
       "21806           0\n",
       "27706           0\n",
       "3               0\n",
       "31706           0\n",
       "43006           0\n",
       "45106           0\n",
       "46006           0\n",
       "48706           0\n",
       "48806           0\n",
       "49006           0\n",
       "64306           0\n",
       "64406           0\n",
       "69206           0\n",
       "final_181706    0\n",
       "final_149406    0\n",
       "final_177106    0\n",
       "final_146206    0\n",
       "final_123506    0\n",
       "final_53506     0\n",
       "final_128306    0\n",
       "final_174406    0\n",
       "final_133206    0\n",
       "final_178306    0\n",
       "final_143306    0\n",
       "final_123406    0\n",
       "final_128106    0\n",
       "final_65606     0\n",
       "final_24106     0\n",
       "final_61006     0\n",
       "final_111106    0\n",
       "final_52606     0\n",
       "final_63206     0\n",
       "final_137906    0\n",
       "final_175706    0\n",
       "final_123806    0\n",
       "final_127606    0\n",
       "final_181106    0\n",
       "final_111306    0\n",
       "final_164406    0\n",
       "final_101706    0\n",
       "final_71606     0\n",
       "final_181206    0\n",
       "final_135106    0\n",
       "final_138806    0\n",
       "final_46106     0\n",
       "final_46206     0\n",
       "final_133006    0\n",
       "final_63406     0\n",
       "final_175506    0\n",
       "final_183206    0\n",
       "final_147206    0\n",
       "final_101406    0\n",
       "final_175206    0\n",
       "final_170106    0\n",
       "final_147906    0\n",
       "final_142506    0\n",
       "final_183406    0\n",
       "final_117806    0\n",
       "final_102006    0\n",
       "final_38506     0\n",
       "final_117906    0\n",
       "final_118006    0\n",
       "final_39006     0\n",
       "final_167106    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_KNN = predict(clean_df)\n",
    "clean_KNN.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5d1663",
   "metadata": {},
   "source": [
    "Everything looks good, so I run my model on this new df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cbd559a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR score:  0.5\n",
      "precision:  0.5125000000000001\n",
      "recall:  0.5\n",
      "f1:  0.4756944444444444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\herat\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\herat\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "Xp = clean_KNN.drop(['polity', 'country_name', 'region'],axis=1)\n",
    "yp = clean_KNN['polity']\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xp, yp, test_size = 0.145, \n",
    "                                                    random_state = 100)\n",
    "numericals_train = X_train.select_dtypes(np.number)\n",
    "numericals_test = X_test.select_dtypes(np.number)\n",
    "\n",
    "categoricals_train = X_train.select_dtypes(object)\n",
    "categoricals_test = X_test.select_dtypes(object)\n",
    "\n",
    "transformer = StandardScaler().fit(numericals_train)\n",
    "numericals_train_standardized = transformer.transform(numericals_train)\n",
    "numericals_test_standardized = transformer.transform(numericals_test)\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown='error', drop='first').fit(categoricals_train)\n",
    "categoricals_train_encoded = encoder.transform(categoricals_train).toarray()\n",
    "categoricals_test_encoded = encoder.transform(categoricals_test).toarray()\n",
    "\n",
    "X_train = np.concatenate((numericals_train_standardized,categoricals_train_encoded),axis=1)\n",
    "X_test = np.concatenate((numericals_test_standardized,categoricals_test_encoded),axis=1)\n",
    "\n",
    "LR = LogisticRegression(random_state=42, solver='saga', max_iter = 10000)\n",
    "LR.fit(X_train, y_train)\n",
    "\n",
    "LR_pred = LR.predict(X_test)\n",
    "\n",
    "print('LR score: ', LR.score(X_test, y_test))\n",
    "print(\"precision: \",precision_score(y_test, LR_pred, average='weighted'))\n",
    "print(\"recall: \",recall_score(y_test, LR_pred, average='weighted'))\n",
    "print(\"f1: \",f1_score(y_test, LR_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a333f4",
   "metadata": {},
   "source": [
    "My model gets better!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0812250",
   "metadata": {},
   "source": [
    "#### Real score Vs. predicted one: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7e2a6997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polity</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-7.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-7.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-7.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8.0</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-10.0</td>\n",
       "      <td>-10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    polity  prediction\n",
       "0      7.0         8.0\n",
       "1     -7.0        10.0\n",
       "2      6.0        -2.0\n",
       "3     10.0        10.0\n",
       "4     -1.0        -3.0\n",
       "5     -7.0         9.0\n",
       "6     10.0        10.0\n",
       "7     -4.0        -4.0\n",
       "8     10.0        10.0\n",
       "9      9.0         9.0\n",
       "10    -7.0         7.0\n",
       "11     7.0         8.0\n",
       "12     7.0         5.0\n",
       "13    -7.0         9.0\n",
       "14    10.0        10.0\n",
       "15    10.0        10.0\n",
       "16    10.0         8.0\n",
       "17     8.0         8.0\n",
       "18     8.0        -3.0\n",
       "19     6.0         5.0\n",
       "20     9.0         9.0\n",
       "21     9.0         9.0\n",
       "22     6.0         6.0\n",
       "23   -10.0       -10.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_pred = LR.predict(X_test)\n",
    "y_test = pd.DataFrame(y_test).reset_index(drop = True)\n",
    "LR_pred = pd.DataFrame(LR_pred).reset_index(drop = True)\n",
    "pd.concat([y_test, LR_pred], axis = 1).rename(columns = {0: 'prediction'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "002b439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfc4b00",
   "metadata": {},
   "source": [
    "#### Comparing models to choose best one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd2efbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Scores_1 = [R1, PS1, RS1, F1_1, KNN1]\n",
    "Scores_2 = [R2, PS2, RS2, F1_2, KNN2]\n",
    "Scores_3 = [R3, PS3, RS3, F1_3, KNN3]\n",
    "\n",
    "df1 = pd.DataFrame(Scores_1, index = ['R_Score', 'Precision', 'Recall', 'F1', 'KNN_score'], \n",
    "             columns = ['Model 1'])\n",
    "df2 = pd.DataFrame(Scores_2, index = ['R_Score', 'Precision', 'Recall', 'F1', 'KNN_score'], \n",
    "             columns = ['Model 2'])\n",
    "df3 = pd.DataFrame(Scores_3, index = ['R_Score', 'Precision', 'Recall', 'F1', 'KNN_score'], \n",
    "             columns = ['Model 3'])\n",
    "\n",
    "scores = pd.concat([df1, df2, df3], axis = 1).T.reset_index()\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2fbef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = scores.melt(id_vars = ['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54384257",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = scores.pivot_table(index = ['index', 'variable'], values = 'value').reset_index()\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d1010b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data = scores, x = 'value', y = 'index', hue = 'variable', kind = 'bar', palette = 'rocket')\n",
    "plt.grid(axis = 'y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ac4754",
   "metadata": {},
   "source": [
    "This plot shows that the 3rd model has the best Logistic Regression Scores, and it also shows the KNN model doesn't work well with this dataset.\n",
    "This is why I choose that the best way to deal with NaNs is predicting their value with the KNN model, and the best model to predict my target is Logistic Regrerssion."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
